# vocab
vectorizer <- vocab_vectorizer(vocab)
dtm_train = create_dtm(covid_train, vectorizer)
#dtm_train
NFOLDS = 4
head(covidclass_labels)
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$labels,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
prep_fun <- tolower
it_test = tok_fun(prep_fun(test$chief.complaint))
it_test = itoken(it_test, ids = test$patientID, progressbar = FALSE)
it_test
dtm_test = create_dtm(it_test, vectorizer)
head(test$labels)
preds =  predict(glmnet_classifier, dtm_test, type = 'response')[,1]
#table(test$chief.complaint[preds>0.2])
#Using text2vec example as guide
# Labeled data with week 6 predictions
#Transform to data.table set key to id
week_6_results <- setDT(model_example)
#clean data for processing
#Make chief complaints characters (were factors)
#Rename cc1.x to chief_complaints
week_6_results$cc1.x <- as.character(week_6_results$cc1.x)
week_6_results <- week_6_results %>%
rename(chief_complaints = cc1.x)
setkey(week_6_results, id)
#Set seed and divid data with labels into test and train data
set.seed(888)
all_ids_2 <-  week_6_results$id
train_ids_2 <- sample(all_ids_2, 1300)
test_ids_2 <- setdiff(all_ids_2, train_ids_2)
train_2 <-  week_6_results[J(train_ids_2)]
test_2 <-  week_6_results[J(test_ids_2)]
train(x = as.factor(dtm_train),
y = train$labels,
method = "rf",
metric = "RMSE",
tuneGrid = tunegrid
)
train(x = dtm_train,
y = train$labels,
method = "rf",
metric = "RMSE",
tuneGrid = tunegrid
)
# Create tunegrid for mtry to tune the model.
tunegrid <- data.frame(.mtry=c(2,4,6, 10, 15, 20, 2))
train(x = dtm_train,
y = train$labels,
method = "rf",
metric = "RMSE",
tuneGrid = tunegrid
)
train(x = dtm_train,
y = train$labels,
method = "rf",
metric = "RMSE"
)
train$labels
train(x = dtm_train,
y = as.factor(train$labels),
method = "rf",
metric = "RMSE"
)
train(x = dtm_train,
y = as.factor(train$labels),
method = "rf"
)
train(x = as.matrix(dtm_train),
y = as.factor(train$labels),
method = "rf"
)
#train random forest model:
rando_for_model = train(x = as.matrix(dtm_train),
y = as.factor(train$labels),
method = "rf"
)
summary(pROC_obj)
clear
#get relevant libraries
library(tidyverse)
library(forcats)
#install.packages("caret")
library(caret)
#install.packages("rlang")
#install.packages("cvms")
#install.packages("cvms")
library(cvms)
#install.packages("tidyr")
library(tidyr)
library(broom)
library(tibble)
#install.packages("here")
library(here)
#library(tidytext)
#install.packages("ggimage")
library(ggimage)
#install.packages("rsvg")
library(rsvg)
#library(textstem)
library(text2vec)
library(data.table)
#install.packages("glmnet")
library(glmnet)
library(ROCR)
library(pROC)
search_assign_by_cc <- function(data, search_terms, column_to_search) {
pasted_match <- paste(search_terms, collapse = "|")
searched_and_assigned <- data %>%
mutate(covid_guess = as.integer(grepl(pattern = pasted_match, x = column_to_search, ignore.case = TRUE)))
return(searched_and_assigned)
}
covid_prediction_count <- function(data) {
prediction_count <- data %>%
group_by(covid_guess) %>%
summarise(count = n())
return(prediction_count)
}
covid_model_comparison <- function(data_predictions, data_w_labels) {
only_labeled_rows <- data_w_labels %>%
filter(label == "0"| label == "1")
joined_data <- only_labeled_rows %>%
left_join(data_predictions, by = "id")
joined_data$label <- as.numeric(joined_data$label)
renamed_joined_data <- joined_data %>%
rename(
covid_status = label,
covid_prediction = covid_guess
)
error_analysis <- renamed_joined_data %>%
mutate(results =  case_when(
covid_status == 0 & covid_prediction == 0 ~ "True Negative",
covid_status == 1 & covid_prediction == 1 ~ "True Positive",
covid_status == 0 & covid_prediction == 1 ~ "False Positive",
covid_status == 1 & covid_prediction == 0 ~ "False Negative"
)
)
return(error_analysis)
}
covid_model_comparison_table <- function(data_with_status_and_prediction){
real_and_prediction <- data_with_status_and_prediction %>%
group_by(covid_status, covid_prediction) %>%
summarise(count = n())
return(real_and_prediction)
}
evaluation_table <- function(covid_model){
model_basic_table <- data.frame("target" = c(covid_model$covid_status),
"prediction"= c(covid_model$covid_prediction))
model_eval <- evaluate(model_basic_table,
target_col = "target",
prediction_col = "prediction",
type = "binomial")
return(model_eval)
}
#Function to sort results by cc
cc_by_results <- function(model, results_factor, cc_number_to_return = 10) {
results_filtered <- model %>%
filter(results == results_factor)
top_cc <- results_filtered%>%
group_by(results, cc1.x) %>%
summarise(count = n()) %>%
arrange(desc(count)) %>%
head(cc_number_to_return)
return(print(top_cc))
}
#read in data and print
covidclass_without_labels <- read.table("./data_do_not_alter/covidclass_without_labels.csv",
na.strings = "", header = TRUE, sep = "\t")
#,
covidclass_w_labels <- read.table("./data_do_not_alter/covidclass_30_percent_labels.csv",
na.strings = "", header = TRUE, sep = "\t")
colnames(covidclass_without_labels)[1] <- "patientID|chief complaint|"
clean_data <- covidclass_without_labels %>%
mutate(id_cc = `patientID|chief complaint|`)
clean_data <- clean_data %>%
separate(col = id_cc, into = c('id', 'cc1', 'cc2'), sep = "[|]", remove = F)
clean_data$cc1[which(clean_data$cc1 == "")] = "No CC provided"
clean_data$cc1 <- as_factor(clean_data$cc1)
colnames(covidclass_w_labels)[1] <- "patientID|labels|chief complaint|"
clean_labeled_data <- covidclass_w_labels %>%
mutate(id_label_cc = `patientID|labels|chief complaint|`)
clean_labeled_data <- clean_labeled_data %>%
separate(col = id_label_cc, into = c('id', 'label', 'cc1', 'cc2'), sep = "[|]", remove = F)
clean_labeled_data$cc1[which(clean_labeled_data$cc1 == "")] = "No CC provided"
clean_labeled_data$cc1 <- as_factor(clean_labeled_data$cc1)
cc_to_match <- c("short", "fever", "i l i", " ili ", "\\bili\\b","influe", "covid", "HYPOXIA", "DYSPNEA", "SOB", "cough", "DOE")
predicted_covid_1 <- search_assign_by_cc(clean_data, cc_to_match, clean_data$cc1)
covid_prediction_counts_1 <- covid_prediction_count(predicted_covid_1)
covid_prediction_counts_1
model_1 <- covid_model_comparison(predicted_covid_1, clean_labeled_data)
model_1_table <- covid_model_comparison_table(model_1)
model_1_table
model_1_evaluated <- evaluation_table(model_1)
model_1_evaluated
plot_confusion_matrix(model_1_evaluated, palette = "Greens")
tp_model_1 <- cc_by_results(model_1, "True Positive")
tn_model_1 <- cc_by_results(model_1, "True Negative")
fp_model_1 <- cc_by_results(model_1, "False Positive")
fn_model_1 <- cc_by_results(model_1, "False Negative")
all_results_model_1 <- bind_rows(tp_model_1, tn_model_1, fp_model_1, fn_model_1)
all_results_model_1_wide <- pivot_wider(all_results_model_1, names_from = results, values_from = count, values_fill = 0)
#Beyond top ten
all_results_model_1_wide_tc <-  model_1 %>%
select(id, cc1.x, results) %>%
group_by(cc1.x, results) %>%
summarise(count = n()) %>%
pivot_wider(names_from = results, values_from = count, values_fill = 0) %>%
rowwise() %>%
mutate(total = sum(`True Positive`, `False Negative`, `True Negative`, `False Positive`)) %>%
mutate(condition_present = sum(`True Positive`, `False Negative`)) %>%
mutate(cc_pct_positive = round(condition_present/total * 100))
cc_to_match_a1 <- c("short", "fever", "i l i", " ili ", "\\bili\\b","influe", "covid", "HYPOXIA", "DYSPNEA", "SOB", "cough", "DOE", "Flu-like symptoms", "chest pain", "hypoxemia", "body aches", "diarrhea", "weakness")
cc_to_match_a2 <- c("fever*","shor", "sob", "hypox", "pnea", "doe", "resp", "pulse ox", "i l i", "\\bili\\b","flu", "cough*", "pneumothorax", "FOUND DOWN", "BODY ACHES", "Chest Pain", "diarrhea", "syncope", "lethargy", "transfer", "CP", "weak", "confusion", "CT", "Tomography", "back pain", "HALLUCINATING")
#chosen search term vector
cc_to_match_example <- cc_to_match_a2
#Do not modify anything below here.
predicted_covid_example <- search_assign_by_cc(clean_data, cc_to_match_example, clean_data$cc1)
covid_prediction_counts_example <- covid_prediction_count(predicted_covid_example)
covid_prediction_counts_example
model_example <- covid_model_comparison(predicted_covid_example, clean_labeled_data)
model_example_table <- covid_model_comparison_table(model_example)
model_example_table
model_example_evaluated <- evaluation_table(model_example)
plot_confusion_matrix(model_example_evaluated, palette = "Greens")
tp_model_example <- cc_by_results(model_example, "True Positive", 50)
tn_model_example <- cc_by_results(model_example, "True Negative", 50)
fp_model_example <- cc_by_results(model_example, "False Positive", 50)
fn_model_example <- cc_by_results(model_example, "False Negative", 50)
tp_model_example
tn_model_example
fp_model_example
fn_model_example
all_results <- bind_rows(tp_model_example, tn_model_example, fp_model_example, fn_model_example)
all_results_wide <- pivot_wider(all_results, names_from = results, values_from = count, values_fill = 0)
comparison_new_model_to_model_1 <- bind_rows(model_example_evaluated, model_1_evaluated)
examine_false_negatives <- all_results_wide %>% arrange(desc(`False Negative`))
comparison_new_model_to_model_1
#Beyond top ten
all_results_model_example <-  model_example %>%
select(id, cc1.x, results) %>%
group_by(cc1.x, results) %>%
summarise(count = n()) %>%
pivot_wider(names_from = results, values_from = count, values_fill = 0) %>%
rowwise() %>%
mutate(total = sum(`True Positive`, `False Negative`, `True Negative`, `False Positive`)) %>%
mutate(condition_present = sum(`True Positive`, `False Negative`)) %>%
mutate(cc_pct_positive = round(condition_present/total * 100))
model_by_threshold <-  all_results_model_example %>%
filter(cc_pct_positive > 5)
group_predictions_wk6 <- predicted_covid_example %>% select(1,6)
write_csv(group_predictions_wk6, "./analysis/group3_predictions_wk6.csv")
sessionInfo()
#First vectorize the text
prep_fun <-  tolower
tok_fun <-  word_tokenizer
covidclass_labels <- read.table("./data_do_not_alter/covidclass_30_percent_labels.tsv",
header = TRUE, sep = "\t")
sum(is.na(covidclass_labels$labels))
train_ids <- covidclass_labels$patientID[!is.na(covidclass_labels$labels)]
test_ids <- covidclass_labels$patientID[is.na(covidclass_labels$labels)]
head(train_ids)
head(train)
train <- covidclass_labels[train_ids,]
test <- covidclass_labels[test_ids,]
train$chief.complaint <- as.character(train$chief.complaint)
names(covidclass_labels)
covid_train <- itoken(train$chief.complaint,preprocessor = tolower, tokenizer = word_tokenizer,
ids = train_ids, progressbar = FALSE)
vocab <- create_vocabulary(covid_train)
# train
# vocab
vectorizer <- vocab_vectorizer(vocab)
dtm_train = create_dtm(covid_train, vectorizer)
#dtm_train
NFOLDS = 4
head(covidclass_labels)
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$labels,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
prep_fun <- tolower
it_test = tok_fun(prep_fun(test$chief.complaint))
it_test = itoken(it_test, ids = test$patientID, progressbar = FALSE)
it_test
dtm_test = create_dtm(it_test, vectorizer)
head(test$labels)
preds =  predict(glmnet_classifier, dtm_test, type = 'response')[,1]
#table(test$chief.complaint[preds>0.2])
#Using text2vec example as guide
# Labeled data with week 6 predictions
#Transform to data.table set key to id
week_6_results <- setDT(model_example)
#clean data for processing
#Make chief complaints characters (were factors)
#Rename cc1.x to chief_complaints
week_6_results$cc1.x <- as.character(week_6_results$cc1.x)
week_6_results <- week_6_results %>%
rename(chief_complaints = cc1.x)
setkey(week_6_results, id)
#Set seed and divid data with labels into test and train data
set.seed(888)
all_ids_2 <-  week_6_results$id
train_ids_2 <- sample(all_ids_2, 1300)
test_ids_2 <- setdiff(all_ids_2, train_ids_2)
train_2 <-  week_6_results[J(train_ids_2)]
test_2 <-  week_6_results[J(test_ids_2)]
# define preprocessing function and tokenization function
prep_fun <-  tolower
tok_fun <-  word_tokenizer
it_train_2 <- itoken(train_2$chief_complaints,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$id,
progressbar = FALSE)
vocab_2 <- create_vocabulary(it_train_2)
vectorizer_2 <- vocab_vectorizer(vocab_2)
dtm_train_2  <-  create_dtm(it_train_2, vectorizer_2)
NFOLDS <-  4
glmnet_classifier_2 <-  cv.glmnet(x = dtm_train_2, y = train_2[['covid_status']],
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
plot(glmnet_classifier_2)
it_test_2 <-  tok_fun(prep_fun(test_2$chief_complaints))
it_test_2  <-  itoken(it_test_2, ids = test_2$id, progressbar = FALSE)
dtm_test_2 <-  create_dtm(it_test_2, vectorizer_2)
preds_2  <-  predict(glmnet_classifier_2, dtm_test_2, type = 'response')[,1]
predict_table <-  data.frame(preds_2)
predict_with_id <- rownames_to_column(predict_table, var = "id")
predict_w_id_status <-  predict_with_id %>%
left_join(clean_labeled_data, by = "id")
#Source https://rviews.rstudio.com/2019/03/01/some-r-packages-for-roc-curves/
#Week 7 roc curve with package ROCR
pred_week_7 <- prediction(predict_w_id_status$preds_2, predict_w_id_status$label)
perf_week_7 <- performance(pred_week_7,"tpr","fpr")
plot(perf_week_7,colorize=FALSE)
#Week 7 roc curve with package pROC
pROC_obj <- roc(predict_w_id_status$label, predict_w_id_status$preds_2,
smoothed = TRUE,
# arguments for ci
ci=TRUE, ci.alpha=0.9, stratified=FALSE,
# arguments for plot
plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")
head(clean_labeled_data)
week_7_predictions <-  tok_fun(prep_fun(clean_labeled_data$cc1))
week_7_predictions  <-  itoken(week_7_predictions, ids = week_7_predictions$id, progressbar = FALSE)
dtm_week_7_predictions <-  create_dtm(week_7_predictions, vectorizer_2)
week_7_preds  <-  predict(glmnet_classifier_2, dtm_week_7_predictions, type = 'response')[,1]
head(clean_labeled_data)
week_7_predictions <-  tok_fun(prep_fun(clean_labeled_data$cc1))
week_7_predictions  <-  itoken(week_7_predictions, ids = week_7_predictions$id, progressbar = FALSE)
dtm_week_7_predictions <-  create_dtm(week_7_predictions, vectorizer_2)
week_7_preds  <-  predict(glmnet_classifier_2, dtm_week_7_predictions, type = 'response')[,1]
predictions_final_week_7 <-  data.frame(week_7_preds)
predictions_final_week_7 <- rownames_to_column(predictions_final_week_7, var = "id")
head(predictions_final_week_7)
dim(predictions_final_week_7)
predictions_final_week_7 <- predictions_final_week_7 %>%
left_join(clean_labeled_data, by = "id")
plot_wk_7 <- predictions_final_week_7 %>%
ggplot(aes(week_7_preds)) + geom_histogram()
plot_wk_7
summary(predictions_final_week_7$week_7_preds)
cutoff <- 0.07
predictions_final_week_7 <- predictions_final_week_7 %>%
mutate(wk_7_pred_label =
case_when(
week_7_preds < cutoff ~ 0,
week_7_preds >= cutoff ~ 1
))
predictions_final_week_7 <- predictions_final_week_7 %>%
mutate(wk_7_pred_label =
case_when(
week_7_preds < cutoff ~ 0,
week_7_preds >= cutoff ~ 1
))
#Week 6
model_example_evaluated
#Week 7 Training data
week_7_stats <- predictions_final_week_7 %>%
filter(label == 0 | label == 1)
week_7_table <- data.frame("target" = c(week_7_stats$label),
"prediction"= c(week_7_stats$wk_7_pred_label))
week_7_table_evaluted <- evaluate(week_7_table,
target_col = "target",
prediction_col = "prediction",
type = "binomial")
week_7_table_evaluted
predictions_final_week_7 <-  rename(predictions_final_week_7, covid_status = label)
predictions_final_week_7 <-  rename(predictions_final_week_7, covid_prediction = wk_7_pred_label)
predictions_final_week_7 <-  rename(predictions_final_week_7, cc1.x = cc1)
predictions_final_week_7 <-  predictions_final_week_7 %>%
mutate(results =  case_when(
covid_status == 0 & covid_prediction == 0 ~ "True Negative",
covid_status == 1 & covid_prediction == 1 ~ "True Positive",
covid_status == 0 & covid_prediction == 1 ~ "False Positive",
covid_status == 1 & covid_prediction == 0 ~ "False Negative"
)
)
tp_wk_7 <- cc_by_results(predictions_final_week_7, "True Positive")
tn_wk_7 <- cc_by_results(predictions_final_week_7, "True Negative")
fp_wk_7 <- cc_by_results(predictions_final_week_7, "False Positive")
fn_wk_7 <- cc_by_results(predictions_final_week_7, "False Negative")
#Our COVID prediction is labeled in the column "wk_7_pred_label"
group3_predictions_wk7 <- predictions_final_week_7
write_csv(group3_predictions_wk7, "./analysis/group3_predictions_wk7.csv")
library(cutpointr)
install.packages("cutpointr")
library(cutpointr)
week_7_preds
week_7_preds  <-  predict(glmnet_classifier_2, dtm_week_7_predictions, type = 'response')[,1]
head(clean_labeled_data)
week_7_predictions <-  tok_fun(prep_fun(clean_labeled_data$cc1))
week_7_predictions  <-  itoken(week_7_predictions, ids = week_7_predictions$id, progressbar = FALSE)
dtm_week_7_predictions <-  create_dtm(week_7_predictions, vectorizer_2)
week_7_preds  <-  predict(glmnet_classifier_2, dtm_week_7_predictions, type = 'response')[,1]
predictions_final_week_7 <-  data.frame(week_7_preds)
predictions_final_week_7 <- rownames_to_column(predictions_final_week_7, var = "id")
head(predictions_final_week_7)
dim(predictions_final_week_7)
predictions_final_week_7 <- predictions_final_week_7 %>%
left_join(clean_labeled_data, by = "id")
plot_wk_7 <- predictions_final_week_7 %>%
ggplot(aes(week_7_preds)) + geom_histogram()
plot_wk_7
summary(predictions_final_week_7$week_7_preds)
cutoff <- 0.07
predictions_final_week_7 <- predictions_final_week_7 %>%
mutate(wk_7_pred_label =
case_when(
week_7_preds < cutoff ~ 0,
week_7_preds >= cutoff ~ 1
))
#Week 6
model_example_evaluated
#Week 7 Training data
week_7_stats <- predictions_final_week_7 %>%
filter(label == 0 | label == 1)
week_7_table <- data.frame("target" = c(week_7_stats$label),
"prediction"= c(week_7_stats$wk_7_pred_label))
week_7_table_evaluted <- evaluate(week_7_table,
target_col = "target",
prediction_col = "prediction",
type = "binomial")
week_7_table_evaluted
predictions_final_week_7 <-  rename(predictions_final_week_7, covid_status = label)
predictions_final_week_7 <-  rename(predictions_final_week_7, covid_prediction = wk_7_pred_label)
predictions_final_week_7 <-  rename(predictions_final_week_7, cc1.x = cc1)
predictions_final_week_7 <-  predictions_final_week_7 %>%
mutate(results =  case_when(
covid_status == 0 & covid_prediction == 0 ~ "True Negative",
covid_status == 1 & covid_prediction == 1 ~ "True Positive",
covid_status == 0 & covid_prediction == 1 ~ "False Positive",
covid_status == 1 & covid_prediction == 0 ~ "False Negative"
)
)
tp_wk_7 <- cc_by_results(predictions_final_week_7, "True Positive")
tn_wk_7 <- cc_by_results(predictions_final_week_7, "True Negative")
fp_wk_7 <- cc_by_results(predictions_final_week_7, "False Positive")
fn_wk_7 <- cc_by_results(predictions_final_week_7, "False Negative")
setwd("~/Desktop/Capstone/smart_py/nhanes_data/convert_nhanes_data 2")
knitr::opts_chunk$set(echo = TRUE)
demographic_data <- sasxport.get("DEMO_J.XPT")
# in R
library(Hmisc)
demographic_data <- sasxport.get("DEMO_J.XPT")
demographic_data
demographic_data
write.csv(demographic_data, "demographic_data.csv")
demographic_data
activ_data
depres_data <- sasxport.get("DPQ_J.XPT")
activ_data <- sasxport.get("PAQ_J.XPT")
activ_data
demographic_data
